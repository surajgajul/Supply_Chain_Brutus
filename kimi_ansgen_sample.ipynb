{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3654e380-72b6-4fa9-b209-cb16440e6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4e9325-b8cb-44f6-b140-cdbff5a5c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_db = MilvusClient(\"./milvus_large3.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661f234a-861a-4f24-b5bd-7e46f4e8a51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493eb99d-7a2e-4ec3-b8ad-ed1dca66fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an instruct fine tuning assistant that generates data for supply chain management. Your task is to create answers to a set of questions that will be used to teach undergraduate, graduate, and executive students the principles of logistics, operations, and supply chain management.\n",
    "Ensure answers are comprehensive yet precise, concise, and grounded in pre-trained knowledge and industry best practices. Tailor responses to be clear, actionable, and contextually relevant to the subject matter, avoiding unnecessary jargon. Focus on accuracy and clarity while maintaining a balance between depth and brevity to support diverse learning needs.\n",
    "\n",
    "Guidelines:\n",
    "- Provide comprehensive responses that teach the concepts clearly and practically\n",
    "- Make explanations suitable for business professionals (like supply chain analyst or manager)\n",
    "- Base all answers on the provided text context\n",
    "- Just give the answer, no additional text or formatting\n",
    "- Answer in approximately 180 to 230 words, be concise but complete and avoid unnecessary elaboration or repetition.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d112e43-fa84-42cb-bdbe-c8caaf3754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_embed = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_embed3lrg_API_KEY\"),  \n",
    "  api_version = \"2024-10-21\",\n",
    "  azure_endpoint = os.getenv(\"AZURE_embed3lrg_API_BASE\") \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ddb6ca4-02f6-4236-854c-c6af0e4ade99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    " \n",
    "client_kimi = OpenAI(\n",
    "    api_key = os.getenv(\"MOONSHOT_API_KEY\"),\n",
    "    base_url = os.getenv(\"MOONSHOT_API_BASE\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71bd729d-d0c6-477b-a906-6c8f30ca28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_func(ques):\n",
    "    response = client_embed.embeddings.create(\n",
    "                        input = q,\n",
    "                        model= \"text-embedding-3-large\"\n",
    "                    )\n",
    "    search_res = client_db.search(\n",
    "        collection_name=\"all_supply_chain_books\",\n",
    "        data=[\n",
    "            response.data[0].embedding\n",
    "        ],  \n",
    "        limit=5,  \n",
    "        search_params={\"metric_type\": \"COSINE\", \"params\": {}},  \n",
    "        output_fields=[\"text\"],  \n",
    "    )\n",
    "    retrieved_lines_with_distances = [\n",
    "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
    "    ]\n",
    "    # print(json.dumps(retrieved_lines_with_distances, indent=4))\n",
    "    context = \"\\n\".join([line_with_distance[0] for line_with_distance in retrieved_lines_with_distances])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9d1cd-5144-47a2-93f0-a260e5403376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# start_index = 0   # Question 10 (0-based index)\n",
    "# end_index = 4    # Up to but not including index 12 (Question 12)\n",
    "\n",
    "with open(\"generated_questions.jsonl\", \"r\") as f, open(\"output.jsonl\", \"w\") as outfile:\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        # if i >= start_index and i < end_index:\n",
    "        data = json.loads(line)\n",
    "        # questions.append(data['question'])\n",
    "        q = data['question']\n",
    "        # print(q)\n",
    "        context = context_func(q)\n",
    "        USER_PROMPT = f\"\"\"\n",
    "        Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "        <question>\n",
    "        {q}\n",
    "        </question>\n",
    "        \"\"\"\n",
    "        response = client_kimi.chat.completions.create(\n",
    "            model=\"kimi-k2-0711-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "            ],\n",
    "            temperature = 0.4,\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        # print(answer)\n",
    "        # print(\"=\"*150)\n",
    "        data['answer'] = answer\n",
    "        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "                \n",
    "        # elif i >= end_index:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad3b88-2bc1-4a27-91cf-bf9cbbbd62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in questions:\n",
    "#     print(q)\n",
    "#     context = context_func(q)\n",
    "#     USER_PROMPT = f\"\"\"\n",
    "#     Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n",
    "#     <context>\n",
    "#     {context}\n",
    "#     </context>\n",
    "#     <question>\n",
    "#     {q}\n",
    "#     </question>\n",
    "#     \"\"\"\n",
    "#     response = client_kimi.chat.completions.create(\n",
    "#         model=\"kimi-k2-0711-preview\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "#             {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "#         ],\n",
    "#         temperature = 0.4,\n",
    "#     )\n",
    "#     answer = response.choices[0].message.content.strip()\n",
    "#     print(answer)\n",
    "#     print(\"=\"*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc7c4a-0541-41b7-af91-41c73010ef06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
